{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551282d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib\n",
    "scipy\n",
    "numpy\n",
    "scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566bfa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p opt/ml/model  \n",
    "!cp model.pkl opt/ml/model/model.pkl\n",
    "!cp tfidf_vectorizer.pkl opt/ml/model/tfidf_vectorizer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa42654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import boto3\n",
    "\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.pkl\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        return input_data\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned data from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    # Process the input data if necessary\n",
    "    processed_data = process_input(input_data, model)\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(processed_data)\n",
    "    return predictions\n",
    "\n",
    "def process_input(input_data, model):\n",
    "    # Process input data as needed before passing to the model for prediction\n",
    "    X = input_data['url']\n",
    "    vectorizer = joblib.load(os.path.join(\"opt/ml/model\", \"tfidf_vectorizer.pkl\"))\n",
    "    X_vect = vectorizer.transform(X)\n",
    "    return X_vect\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    prediction_str = prediction[0]\n",
    "    response = {\"type\": prediction_str}\n",
    "    return json.dumps(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a312d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.2.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.2.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['phishing']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import boto3\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.pkl\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        return input_data\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned data from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    # Process the input data if necessary\n",
    "    processed_data = process_input(input_data)\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(processed_data)\n",
    "    return predictions\n",
    "\n",
    "def process_input(input_data):\n",
    "    # Process input data as needed before passing to the model for prediction\n",
    "    X = input_data['url']\n",
    "    vectorizer = joblib.load(os.path.join(\"opt/ml/model\", \"tfidf_vectorizer.pkl\"))\n",
    "    X_vect = vectorizer.transform(X)\n",
    "    return X_vect\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    prediction_str = prediction[0]\n",
    "    response = {\"type\": prediction_str}\n",
    "    return json.dumps(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test the function\n",
    "    model_dir = \"opt/ml/model\"\n",
    "    model = model_fn(model_dir)\n",
    "    print(predict_fn({'url': [\"http://malicious-site.com\"]}, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684c83a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pkl\n",
      "inference.py\n",
      "tfidf_vectorizer.pkl\n",
      "requirements.txt\n",
      "opt/\n",
      "opt/ml/\n",
      "opt/ml/model/\n",
      "opt/ml/model/tfidf_vectorizer.pkl\n",
      "opt/ml/model/model.pkl\n"
     ]
    }
   ],
   "source": [
    "!tar -cvpzf model.tar.gz model.pkl inference.py tfidf_vectorizer.pkl requirements.txt opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4febbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce69cec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = \"arn:aws:iam::058264168738:role/LabRole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cacaee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve sklearn image\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=region,\n",
    "    version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36bb89c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-058264168738\n"
     ]
    }
   ],
   "source": [
    "#Bucket for model artifacts\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "print(default_bucket)\n",
    "\n",
    "#Upload tar.gz to bucket\n",
    "model_artifacts = f\"s3://{default_bucket}/model.tar.gz\"\n",
    "response = s3.meta.client.upload_file('model.tar.gz', default_bucket, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf8d6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: sklearn-test2024-05-05-06-03-50\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:058264168738:model/sklearn-test2024-05-05-06-03-50\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Model Creation\n",
    "model_name = \"sklearn-test\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + model_name)\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": image_uri,\n",
    "            \"Mode\": \"SingleModel\",\n",
    "            \"ModelDataUrl\": model_artifacts,\n",
    "            \"Environment\": {'SAGEMAKER_SUBMIT_DIRECTORY': model_artifacts,\n",
    "                           'SAGEMAKER_PROGRAM': 'inference.py'} \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d938e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:058264168738:endpoint-config/sklearn-epc2024-05-05-06-04-05\n"
     ]
    }
   ],
   "source": [
    "#Step 2: EPC Creation\n",
    "sklearn_epc_name = \"sklearn-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.t2.medium\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41ab5a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:058264168738:endpoint/sklearn-local-ep2024-05-05-06-04-22\n"
     ]
    }
   ],
   "source": [
    "#Step 3: EP Creation\n",
    "endpoint_name = \"sklearn-local-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02869d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n",
      "{'EndpointName': 'sklearn-local-ep2024-05-05-06-04-22', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:058264168738:endpoint/sklearn-local-ep2024-05-05-06-04-22', 'EndpointConfigName': 'sklearn-epc2024-05-05-06-04-05', 'ProductionVariants': [{'VariantName': 'sklearnvariant', 'DeployedImages': [{'SpecifiedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3', 'ResolvedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:20bb6714740d1b80a6b39b6ae06b928c59b40b394b083f72435b87e59dda0364', 'ResolutionTime': datetime.datetime(2024, 5, 5, 6, 4, 23, 173000, tzinfo=tzlocal())}], 'CurrentWeight': 1.0, 'DesiredWeight': 1.0, 'CurrentInstanceCount': 1, 'DesiredInstanceCount': 1}], 'EndpointStatus': 'InService', 'CreationTime': datetime.datetime(2024, 5, 5, 6, 4, 22, 570000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 5, 5, 6, 8, 52, 376000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '6a4f48f6-d457-4016-abda-e0508b24c7ca', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '6a4f48f6-d457-4016-abda-e0508b24c7ca', 'content-type': 'application/x-amz-json-1.1', 'content-length': '766', 'date': 'Sun, 05 May 2024 06:09:06 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "#Monitor creation\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14562630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'defacement'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# Initialize the SageMaker runtime client\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Define your input data\n",
    "\"\"\"vanderbilt.rivals.com/viewcoach.asp?coach=2079&sport=1&year=2011\tbenign\n",
    "http://peluqueriadeautor.com/index.php?option=com_virtuemart&page=shop.browse&category_id=31&Itemid=70\tdefacement\n",
    "movies.yahoo.com/shop?d=hv&cf=info&id=1800340831\tbenign\n",
    "cyndislist.com/us/pa/counties\tbenign\n",
    "http://www.824555.com/app/member/SportOption.php?uid=guest&langx=gb\tmalware\n",
    "http://www.raci.it/component/user/reset.html\tdefacement\n",
    "https://docs.google.com/spreadsheet/viewform?formkey=dGg2Z1lCUHlSdjllTVNRUW50TFIzSkE6MQ\tphishing\n",
    "psychology.wikia.com/wiki/Phonemes\tbenign\n",
    "\"\"\"\n",
    "input_data = {\n",
    "    'url': [\"http://peluqueriadeautor.com/index.php?option=com_virtuemart&page=shop.browse&category_id=31&Itemid=70\"]\n",
    "}\n",
    "\n",
    "# Convert input data to JSON string\n",
    "payload = json.dumps(input_data)\n",
    "\n",
    "# Specify the endpoint name\n",
    "endpoint_name = 'sklearn-local-ep2024-05-05-06-04-22'\n",
    "\n",
    "# Call the endpoint\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='application/json',\n",
    "                                   Body=payload)\n",
    "\n",
    "# Decode and print the response\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551c30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
